{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22aae4a4a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0         242\n",
       "1         302\n",
       "2         377\n",
       "3          51\n",
       "4         346\n",
       "         ... \n",
       "99995     476\n",
       "99996     204\n",
       "99997    1090\n",
       "99998     225\n",
       "99999     203\n",
       "Name: movie id, Length: 100000, dtype: int64>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ml-100k/u.data\",sep=\"\\t\", header=None)\n",
    "data.columns = ['user id', 'movie id', 'rating', 'timestamp']\n",
    "data['movie id'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie id</th>\n",
       "      <th>movie title</th>\n",
       "      <th>release date</th>\n",
       "      <th>video release date</th>\n",
       "      <th>IMDb URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie id        movie title release date  video release date  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            IMDb URL  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "0          0          1           1  ...        0          0       0        0   \n",
       "1          1          0           0  ...        0          0       0        0   \n",
       "2          0          0           0  ...        0          0       0        0   \n",
       "3          0          0           0  ...        0          0       0        0   \n",
       "4          0          0           0  ...        0          0       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        0        0       0         1    0        0  \n",
       "2        0        0       0         1    0        0  \n",
       "3        0        0       0         0    0        0  \n",
       "4        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"ml-100k/u.item\",\n",
    "                    sep=\"|\", encoding='latin-1', header=None)\n",
    "movies.columns = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL',\n",
    "                 'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy',\n",
    "                 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "                 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anna (1996)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_id_movie = {}\n",
    "for id,row in movies.iterrows():\n",
    "  map_id_movie[row['movie id']] = row['movie title']\n",
    "map_id_movie[1398]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of movies: 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = data['user id'].nunique()\n",
    "num_movies = data['movie id'].nunique()\n",
    "print(\n",
    "    (f\"Number of users: {num_users}\\n\"\n",
    "    f\"Number of movies: {num_movies}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>movie id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24188</th>\n",
       "      <td>299</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>889502902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>347</td>\n",
       "      <td>462</td>\n",
       "      <td>2</td>\n",
       "      <td>881654359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170</th>\n",
       "      <td>96</td>\n",
       "      <td>185</td>\n",
       "      <td>5</td>\n",
       "      <td>884403866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87853</th>\n",
       "      <td>880</td>\n",
       "      <td>302</td>\n",
       "      <td>5</td>\n",
       "      <td>880166451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>177</td>\n",
       "      <td>289</td>\n",
       "      <td>2</td>\n",
       "      <td>880130534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18733</th>\n",
       "      <td>43</td>\n",
       "      <td>215</td>\n",
       "      <td>5</td>\n",
       "      <td>883955467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83494</th>\n",
       "      <td>860</td>\n",
       "      <td>516</td>\n",
       "      <td>3</td>\n",
       "      <td>885991040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36379</th>\n",
       "      <td>313</td>\n",
       "      <td>484</td>\n",
       "      <td>5</td>\n",
       "      <td>891016193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17294</th>\n",
       "      <td>112</td>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "      <td>884992484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71036</th>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>891405958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user id  movie id  rating  timestamp\n",
       "24188      299        88       3  889502902\n",
       "14023      347       462       2  881654359\n",
       "20170       96       185       5  884403866\n",
       "87853      880       302       5  880166451\n",
       "8174       177       289       2  880130534\n",
       "...        ...       ...     ...        ...\n",
       "18733       43       215       5  883955467\n",
       "83494      860       516       3  885991040\n",
       "36379      313       484       5  891016193\n",
       "17294      112       286       4  884992484\n",
       "71036      660         3       1  891405958\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train,data_test = model_selection.train_test_split(data, test_size = 0.1,random_state = 42,stratify = data['rating'])\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model,lr,epochs,Nueralnet = False):\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "  loss_fn = nn.MSELoss()\n",
    "  for t in range(epochs):\n",
    "    model.train()\n",
    "    users = torch.LongTensor(data_train['user id'].to_numpy()) # .cuda()\n",
    "    items = torch.LongTensor(data_train['movie id'].to_numpy()) #.cuda()\n",
    "    ratings = torch.FloatTensor(data_train['rating'].to_numpy())\n",
    "    if Nueralnet:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_pred = model(users,items)\n",
    "    loss_train = loss_fn(y_pred,ratings)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_users = torch.LongTensor(data_test['user id'].to_numpy())\n",
    "        test_items = torch.LongTensor(data_test['movie id'].to_numpy())\n",
    "        test_ratings = torch.FloatTensor(data_test['rating'].to_numpy())\n",
    "        if Nueralnet:\n",
    "            test_ratings=test_ratings.unsqueeze(1)\n",
    "        pred_test = model(test_users,test_items)\n",
    "        loss_test = loss_fn(pred_test, test_ratings)\n",
    "\n",
    "    print(f\"Epoch {t+1} -- Train loss: {loss_train:>7f} Test loss: {loss_test:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NueralNet(nn.Module):\n",
    "  def __init__(self,users,movie_ids,embed_size):\n",
    "    super(NueralNet,self).__init__()\n",
    "    self.user_embed = nn.Embedding(users,embed_size)\n",
    "    self.movie_embed = nn.Embedding(movie_ids,embed_size)\n",
    "    self.user_embed.weight.data.uniform_(0,0.05)\n",
    "    self.movie_embed.weight.data.uniform_(0,0.05)\n",
    "    self.network = nn.Sequential(\n",
    "            nn.Linear(2*embed_size,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    self.output = nn.Sigmoid()\n",
    "\n",
    "  def forward(self,u,v):\n",
    "    U = self.user_embed(u)\n",
    "    V = self.movie_embed(v)\n",
    "    vector = torch.cat([U,V], dim=-1)\n",
    "    out_temp = self.network(vector)\n",
    "    return self.output(out_temp)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Train loss: 2.756229 Test loss: 2.735536\n",
      "Epoch 2 -- Train loss: 2.735766 Test loss: 2.715558\n",
      "Epoch 3 -- Train loss: 2.715769 Test loss: 2.696153\n",
      "Epoch 4 -- Train loss: 2.696349 Test loss: 2.676896\n",
      "Epoch 5 -- Train loss: 2.677074 Test loss: 2.657388\n",
      "Epoch 6 -- Train loss: 2.657553 Test loss: 2.637375\n",
      "Epoch 7 -- Train loss: 2.637530 Test loss: 2.616712\n",
      "Epoch 8 -- Train loss: 2.616856 Test loss: 2.595331\n",
      "Epoch 9 -- Train loss: 2.595459 Test loss: 2.573069\n",
      "Epoch 10 -- Train loss: 2.573183 Test loss: 2.549415\n",
      "Epoch 11 -- Train loss: 2.549510 Test loss: 2.524169\n",
      "Epoch 12 -- Train loss: 2.524235 Test loss: 2.497763\n",
      "Epoch 13 -- Train loss: 2.497799 Test loss: 2.470616\n",
      "Epoch 14 -- Train loss: 2.470617 Test loss: 2.442293\n",
      "Epoch 15 -- Train loss: 2.442257 Test loss: 2.412512\n",
      "Epoch 16 -- Train loss: 2.412417 Test loss: 2.381458\n",
      "Epoch 17 -- Train loss: 2.381313 Test loss: 2.348821\n",
      "Epoch 18 -- Train loss: 2.348616 Test loss: 2.314405\n",
      "Epoch 19 -- Train loss: 2.314126 Test loss: 2.278155\n",
      "Epoch 20 -- Train loss: 2.277785 Test loss: 2.240196\n",
      "Epoch 21 -- Train loss: 2.239721 Test loss: 2.201637\n",
      "Epoch 22 -- Train loss: 2.201040 Test loss: 2.161444\n",
      "Epoch 23 -- Train loss: 2.160708 Test loss: 2.119263\n",
      "Epoch 24 -- Train loss: 2.118354 Test loss: 2.075105\n",
      "Epoch 25 -- Train loss: 2.073992 Test loss: 2.028948\n",
      "Epoch 26 -- Train loss: 2.027592 Test loss: 1.981941\n",
      "Epoch 27 -- Train loss: 1.980312 Test loss: 1.933358\n",
      "Epoch 28 -- Train loss: 1.931416 Test loss: 1.882980\n",
      "Epoch 29 -- Train loss: 1.880673 Test loss: 1.830998\n",
      "Epoch 30 -- Train loss: 1.828266 Test loss: 1.777657\n",
      "Epoch 31 -- Train loss: 1.774431 Test loss: 1.723267\n",
      "Epoch 32 -- Train loss: 1.719473 Test loss: 1.668210\n",
      "Epoch 33 -- Train loss: 1.663768 Test loss: 1.612916\n",
      "Epoch 34 -- Train loss: 1.607742 Test loss: 1.557901\n",
      "Epoch 35 -- Train loss: 1.551905 Test loss: 1.503774\n",
      "Epoch 36 -- Train loss: 1.496860 Test loss: 1.451198\n",
      "Epoch 37 -- Train loss: 1.443264 Test loss: 1.400871\n",
      "Epoch 38 -- Train loss: 1.391812 Test loss: 1.353501\n",
      "Epoch 39 -- Train loss: 1.343208 Test loss: 1.309769\n",
      "Epoch 40 -- Train loss: 1.298134 Test loss: 1.270288\n",
      "Epoch 41 -- Train loss: 1.257206 Test loss: 1.235555\n",
      "Epoch 42 -- Train loss: 1.220926 Test loss: 1.205902\n",
      "Epoch 43 -- Train loss: 1.189636 Test loss: 1.181456\n",
      "Epoch 44 -- Train loss: 1.163478 Test loss: 1.162105\n",
      "Epoch 45 -- Train loss: 1.142359 Test loss: 1.147483\n",
      "Epoch 46 -- Train loss: 1.125933 Test loss: 1.136985\n",
      "Epoch 47 -- Train loss: 1.113618 Test loss: 1.129818\n",
      "Epoch 48 -- Train loss: 1.104644 Test loss: 1.125056\n",
      "Epoch 49 -- Train loss: 1.098107 Test loss: 1.121729\n",
      "Epoch 50 -- Train loss: 1.093060 Test loss: 1.118918\n",
      "Epoch 51 -- Train loss: 1.088608 Test loss: 1.115834\n",
      "Epoch 52 -- Train loss: 1.083977 Test loss: 1.111869\n",
      "Epoch 53 -- Train loss: 1.078578 Test loss: 1.106629\n",
      "Epoch 54 -- Train loss: 1.072026 Test loss: 1.099937\n",
      "Epoch 55 -- Train loss: 1.064151 Test loss: 1.091814\n",
      "Epoch 56 -- Train loss: 1.054972 Test loss: 1.082430\n",
      "Epoch 57 -- Train loss: 1.044657 Test loss: 1.072061\n",
      "Epoch 58 -- Train loss: 1.033480 Test loss: 1.061049\n",
      "Epoch 59 -- Train loss: 1.021771 Test loss: 1.049755\n",
      "Epoch 60 -- Train loss: 1.009875 Test loss: 1.038539\n",
      "Epoch 61 -- Train loss: 0.998142 Test loss: 1.027771\n",
      "Epoch 62 -- Train loss: 0.986952 Test loss: 1.017647\n",
      "Epoch 63 -- Train loss: 0.976451 Test loss: 1.008356\n",
      "Epoch 64 -- Train loss: 0.966813 Test loss: 1.000005\n",
      "Epoch 65 -- Train loss: 0.958127 Test loss: 0.992588\n",
      "Epoch 66 -- Train loss: 0.950376 Test loss: 0.986037\n",
      "Epoch 67 -- Train loss: 0.943456 Test loss: 0.980200\n",
      "Epoch 68 -- Train loss: 0.937193 Test loss: 0.974904\n",
      "Epoch 69 -- Train loss: 0.931417 Test loss: 0.970182\n",
      "Epoch 70 -- Train loss: 0.926198 Test loss: 0.965843\n",
      "Epoch 71 -- Train loss: 0.921342 Test loss: 0.961801\n",
      "Epoch 72 -- Train loss: 0.916728 Test loss: 0.957931\n",
      "Epoch 73 -- Train loss: 0.912218 Test loss: 0.954175\n",
      "Epoch 74 -- Train loss: 0.907734 Test loss: 0.950497\n",
      "Epoch 75 -- Train loss: 0.903267 Test loss: 0.946907\n",
      "Epoch 76 -- Train loss: 0.898834 Test loss: 0.943438\n",
      "Epoch 77 -- Train loss: 0.894474 Test loss: 0.940133\n",
      "Epoch 78 -- Train loss: 0.890246 Test loss: 0.937028\n",
      "Epoch 79 -- Train loss: 0.886196 Test loss: 0.934173\n",
      "Epoch 80 -- Train loss: 0.882384 Test loss: 0.931589\n",
      "Epoch 81 -- Train loss: 0.878842 Test loss: 0.929281\n",
      "Epoch 82 -- Train loss: 0.875579 Test loss: 0.927258\n",
      "Epoch 83 -- Train loss: 0.872602 Test loss: 0.925515\n",
      "Epoch 84 -- Train loss: 0.869910 Test loss: 0.924005\n",
      "Epoch 85 -- Train loss: 0.867477 Test loss: 0.922700\n",
      "Epoch 86 -- Train loss: 0.865280 Test loss: 0.921569\n",
      "Epoch 87 -- Train loss: 0.863282 Test loss: 0.920547\n",
      "Epoch 88 -- Train loss: 0.861430 Test loss: 0.919585\n",
      "Epoch 89 -- Train loss: 0.859678 Test loss: 0.918643\n",
      "Epoch 90 -- Train loss: 0.857995 Test loss: 0.917693\n",
      "Epoch 91 -- Train loss: 0.856352 Test loss: 0.916712\n",
      "Epoch 92 -- Train loss: 0.854739 Test loss: 0.915709\n",
      "Epoch 93 -- Train loss: 0.853156 Test loss: 0.914693\n",
      "Epoch 94 -- Train loss: 0.851604 Test loss: 0.913681\n",
      "Epoch 95 -- Train loss: 0.850095 Test loss: 0.912687\n",
      "Epoch 96 -- Train loss: 0.848639 Test loss: 0.911724\n",
      "Epoch 97 -- Train loss: 0.847246 Test loss: 0.910795\n",
      "Epoch 98 -- Train loss: 0.845919 Test loss: 0.909904\n",
      "Epoch 99 -- Train loss: 0.844657 Test loss: 0.909052\n",
      "Epoch 100 -- Train loss: 0.843455 Test loss: 0.908228\n",
      "Epoch 101 -- Train loss: 0.842305 Test loss: 0.907436\n",
      "Epoch 102 -- Train loss: 0.841204 Test loss: 0.906668\n",
      "Epoch 103 -- Train loss: 0.840143 Test loss: 0.905931\n",
      "Epoch 104 -- Train loss: 0.839122 Test loss: 0.905227\n",
      "Epoch 105 -- Train loss: 0.838143 Test loss: 0.904559\n",
      "Epoch 106 -- Train loss: 0.837203 Test loss: 0.903924\n",
      "Epoch 107 -- Train loss: 0.836304 Test loss: 0.903319\n",
      "Epoch 108 -- Train loss: 0.835451 Test loss: 0.902745\n",
      "Epoch 109 -- Train loss: 0.834642 Test loss: 0.902207\n",
      "Epoch 110 -- Train loss: 0.833885 Test loss: 0.901710\n",
      "Epoch 111 -- Train loss: 0.833170 Test loss: 0.901239\n",
      "Epoch 112 -- Train loss: 0.832503 Test loss: 0.900795\n",
      "Epoch 113 -- Train loss: 0.831877 Test loss: 0.900377\n",
      "Epoch 114 -- Train loss: 0.831290 Test loss: 0.899976\n",
      "Epoch 115 -- Train loss: 0.830741 Test loss: 0.899590\n",
      "Epoch 116 -- Train loss: 0.830224 Test loss: 0.899214\n",
      "Epoch 117 -- Train loss: 0.829739 Test loss: 0.898852\n",
      "Epoch 118 -- Train loss: 0.829280 Test loss: 0.898495\n",
      "Epoch 119 -- Train loss: 0.828852 Test loss: 0.898138\n",
      "Epoch 120 -- Train loss: 0.828447 Test loss: 0.897779\n",
      "Epoch 121 -- Train loss: 0.828060 Test loss: 0.897423\n",
      "Epoch 122 -- Train loss: 0.827691 Test loss: 0.897073\n",
      "Epoch 123 -- Train loss: 0.827338 Test loss: 0.896722\n",
      "Epoch 124 -- Train loss: 0.826998 Test loss: 0.896366\n",
      "Epoch 125 -- Train loss: 0.826668 Test loss: 0.896010\n",
      "Epoch 126 -- Train loss: 0.826349 Test loss: 0.895651\n",
      "Epoch 127 -- Train loss: 0.826040 Test loss: 0.895291\n",
      "Epoch 128 -- Train loss: 0.825737 Test loss: 0.894931\n",
      "Epoch 129 -- Train loss: 0.825439 Test loss: 0.894573\n",
      "Epoch 130 -- Train loss: 0.825145 Test loss: 0.894223\n",
      "Epoch 131 -- Train loss: 0.824853 Test loss: 0.893881\n",
      "Epoch 132 -- Train loss: 0.824562 Test loss: 0.893548\n",
      "Epoch 133 -- Train loss: 0.824273 Test loss: 0.893222\n",
      "Epoch 134 -- Train loss: 0.823984 Test loss: 0.892910\n",
      "Epoch 135 -- Train loss: 0.823694 Test loss: 0.892612\n",
      "Epoch 136 -- Train loss: 0.823403 Test loss: 0.892326\n",
      "Epoch 137 -- Train loss: 0.823108 Test loss: 0.892050\n",
      "Epoch 138 -- Train loss: 0.822810 Test loss: 0.891787\n",
      "Epoch 139 -- Train loss: 0.822506 Test loss: 0.891533\n",
      "Epoch 140 -- Train loss: 0.822197 Test loss: 0.891282\n",
      "Epoch 141 -- Train loss: 0.821881 Test loss: 0.891040\n",
      "Epoch 142 -- Train loss: 0.821556 Test loss: 0.890804\n",
      "Epoch 143 -- Train loss: 0.821221 Test loss: 0.890571\n",
      "Epoch 144 -- Train loss: 0.820874 Test loss: 0.890341\n",
      "Epoch 145 -- Train loss: 0.820516 Test loss: 0.890109\n",
      "Epoch 146 -- Train loss: 0.820144 Test loss: 0.889871\n",
      "Epoch 147 -- Train loss: 0.819754 Test loss: 0.889626\n",
      "Epoch 148 -- Train loss: 0.819346 Test loss: 0.889375\n",
      "Epoch 149 -- Train loss: 0.818920 Test loss: 0.889108\n",
      "Epoch 150 -- Train loss: 0.818471 Test loss: 0.888831\n",
      "Epoch 151 -- Train loss: 0.818003 Test loss: 0.888546\n",
      "Epoch 152 -- Train loss: 0.817513 Test loss: 0.888223\n",
      "Epoch 153 -- Train loss: 0.817019 Test loss: 0.887888\n",
      "Epoch 154 -- Train loss: 0.816508 Test loss: 0.887583\n",
      "Epoch 155 -- Train loss: 0.815955 Test loss: 0.887259\n",
      "Epoch 156 -- Train loss: 0.815380 Test loss: 0.886927\n",
      "Epoch 157 -- Train loss: 0.814791 Test loss: 0.886580\n",
      "Epoch 158 -- Train loss: 0.814173 Test loss: 0.886214\n",
      "Epoch 159 -- Train loss: 0.813528 Test loss: 0.885841\n",
      "Epoch 160 -- Train loss: 0.812854 Test loss: 0.885467\n",
      "Epoch 161 -- Train loss: 0.812145 Test loss: 0.885089\n",
      "Epoch 162 -- Train loss: 0.811408 Test loss: 0.884709\n",
      "Epoch 163 -- Train loss: 0.810645 Test loss: 0.884316\n",
      "Epoch 164 -- Train loss: 0.809856 Test loss: 0.883903\n",
      "Epoch 165 -- Train loss: 0.809040 Test loss: 0.883485\n",
      "Epoch 166 -- Train loss: 0.808195 Test loss: 0.883053\n",
      "Epoch 167 -- Train loss: 0.807320 Test loss: 0.882614\n",
      "Epoch 168 -- Train loss: 0.806422 Test loss: 0.882174\n",
      "Epoch 169 -- Train loss: 0.805504 Test loss: 0.881753\n",
      "Epoch 170 -- Train loss: 0.804568 Test loss: 0.881350\n"
     ]
    }
   ],
   "source": [
    "model_2 = NueralNet(num_users+1,num_movies+1,64)\n",
    "train_epochs(model_2,0.001,170,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = input(\"Enter the user_id for movie recommendations: \")\n",
    "movie_list = data[data['user id'] == int(user_id)]['movie id'].to_list()\n",
    "unseen_list = [int(x) for x in range(1,num_movies+1) if x not in movie_list]\n",
    "unseen_list = np.array(unseen_list)\n",
    "temp_x = torch.LongTensor(np.full(np.size(unseen_list),int(user_id)))\n",
    "unseen_mov = torch.LongTensor(unseen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Recommended movies by NeuralNetworks--------------\n",
      "Safe Passage (1994) 4.8690386\n",
      "Great Day in Harlem, A (1994) 4.8436623\n",
      "Entertaining Angels: The Dorothy Day Story (1996) 4.8406487\n",
      "Someone Else's America (1995) 4.8394794\n",
      "Santa with Muscles (1996) 4.835436\n",
      "Pather Panchali (1955) 4.8345876\n",
      "The Deadly Cure (1996) 4.8319774\n",
      "Saint of Fort Washington, The (1993) 4.8316827\n",
      "Some Mother's Son (1996) 4.829162\n",
      "Bitter Sugar (Azucar Amargo) (1996) 4.820065\n"
     ]
    }
   ],
   "source": [
    "model_2.eval()\n",
    "predictions_NN = model_2(temp_x,unseen_mov)\n",
    "predictions_NN=predictions_NN.squeeze()\n",
    "sorted_indices = np.argsort(predictions_NN.detach().numpy())[::-1]\n",
    "ordered_movies = unseen_list[sorted_indices]\n",
    "ordered_ratings = predictions_NN.detach().numpy()[sorted_indices]\n",
    "print(\"---------------Recommended movies by NeuralNetworks--------------\")\n",
    "i=0\n",
    "for xyz in ordered_movies[:10]:\n",
    "  print(map_id_movie[xyz],ordered_ratings[i])\n",
    "  i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
